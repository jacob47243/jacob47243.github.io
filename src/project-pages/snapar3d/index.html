<!-- src/project-pages/snapar3d/index.html -->
<section id="project-snapar3d" data-base="/src/project-pages/snapar3d/">
    <style>
      #project-snapar3d { color:#e8e9ea; }
      #project-snapar3d .grid { display:grid; gap:16px; grid-template-columns: 1fr; }
      #project-snapar3d h2 { margin: 6px 0 4px; font-size: 22px; }
      #project-snapar3d h3 { margin: 10px 0 6px; font-size: 16px; color:#a0a3a7; }
      #project-snapar3d p  { margin: 0 0 10px; }
      #project-snapar3d ul { margin: 6px 0 12px; padding-left: 18px; }
      #project-snapar3d li { margin: 4px 0; }
  
      #project-snapar3d .card{
        background:#121315; border:1px solid rgba(255,255,255,.08);
        border-radius:14px; padding:16px;
      }
  
      /* media frame (same as chess arm) */
      .media { display:grid; gap:12px; }
      .media .frame{
        position:relative; border:1px solid rgba(20,184,166,.35); border-radius:12px;
        background:#0f1113; box-shadow:0 12px 40px rgba(0,0,0,.35); overflow:hidden;
        aspect-ratio: 16/9; min-height: 220px;
      }
      .media video, .media iframe { position:absolute; inset:0; width:100%; height:100%; border:0; }
  
      /* button row + buttons (same family as chess arm) */
      .btn-row { display:flex; gap:8px; flex-wrap:wrap; margin-top:6px; }
      .btn{
        display:inline-block; padding:8px 12px; border-radius:10px; font-weight:700;
        border:1px solid rgba(255,255,255,.15); background: var(--accent, #14b8a6);
        color:#111; text-decoration:none;
      }
      .btn:hover{ filter:brightness(1.05); color:#fff; }
  
      /* little tag chips */
      .chip-row{ display:flex; flex-wrap:wrap; gap:8px; margin-top:6px; }
      .chip{
        display:inline-block; padding:4px 10px; border-radius:999px; font-size:12px;
        background:rgba(20,184,166,.10); color:#93f4e5; border:1px solid rgba(20,184,166,.35);
        white-space:nowrap;
      }
    </style>
  
    <!-- Header -->
    <header class="card">
      <h2>SnapAR3D</h2>
      <p>
        SnapAR3D uses AR to guide optimal photo capture and record precise camera poses relative to your object.
        We convert this data for NVIDIA’s nvdiffrast / nvdifrec pipeline to create accurate 3D models.
      </p>
    </header>
  
    <!-- Media -->
    <section class="card media">
      <h3>Demo</h3>
  
      <!-- YouTube embed -->
      <div class="frame">
        <iframe
          src="https://www.youtube.com/embed/9cUk6gcapfg"
          title="SnapAR3D — overview"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; fullscreen"
          allowfullscreen>
        </iframe>
      </div>
  
      <div class="btn-row">
        <a class="btn" href="https://devpost.com/software/snapar3d" target="_blank" rel="noopener">View on Devpost</a>
        <a class="btn" href="https://www.youtube.com/watch?v=9cUk6gcapfg" target="_blank" rel="noopener">Watch on YouTube</a>
      </div>
    </section>
  
    <!-- Narrative blocks -->
    <section class="grid">
      <article class="card">
        <h3>Inspiration</h3>
        <p>
          We were inspired by the growing need for accessible 3D capture and the potential of AR to help users
          take great photos. Guiding viewpoints + capturing poses lets everyday imagery drive high-quality 3D recon.
        </p>
      </article>
  
      <article class="card">
        <h3>What it does</h3>
        <p>
          The app uses AR to guide photo capture and records per-image camera extrinsics. We convert this into
          NeRF-style transforms for nvdifrec, producing accurate meshes/textures from a small number of photos.
        </p>
      </article>
  
      <article class="card">
        <h3>How we built it</h3>
        <ul>
          <li>ARKit/RealityKit to acquire images + device pose.</li>
          <li>COLMAP formatting & a conversion step to NeRF-compatible transforms (JSON).</li>
          <li>Reconstruction via nvdifrec; lightweight host to share <code>transforms.json</code>.</li>
        </ul>
      </article>
  
      <article class="card">
        <h3>Challenges</h3>
        <ul>
          <li>Pose/frame fine-tuning for fidelity vs. speed.</li>
          <li>Coordinate frame differences between ARKit and NeRF conventions.</li>
          <li>Integrating data from multiple sources without drift.</li>
        </ul>
      </article>
  
      <article class="card">
        <h3>Accomplishments</h3>
        <ul>
          <li>AR guidance that helps non-experts capture high-quality inputs.</li>
          <li>Recon quality comparable to heavier pipelines, with faster training time.</li>
        </ul>
      </article>
  
      <article class="card">
        <h3>What we learned</h3>
        <p>
          A deeper understanding of AR pipelines, camera models, and how robust 3D reconstructions emerge from
          careful capture + clean pose data. Also: iterate relentlessly—small data/layout tweaks matter a lot.
        </p>
      </article>
  
      <article class="card">
        <h3>What’s next</h3>
        <ul>
          <li>Smoother on-device capture UI and guidance.</li>
          <li>Better support for diverse objects/scenes and lighting.</li>
          <li>More real-time feedback during capture and conversion.</li>
        </ul>
      </article>
    </section>
  
    <!-- Built With / Skills -->
    <section class="card">
      <h3>Tools</h3>
      <div class="chip-row">
        <span class="chip">ARKit</span>
        <span class="chip">RealityKit</span>
        <span class="chip">Swift</span>
        <span class="chip">SwiftUI</span>
        <span class="chip">COLMAP</span>
        <span class="chip">OpenCV</span>
        <span class="chip">Python</span>
        <span class="chip">JavaScript</span>
        <span class="chip">nvdiffrast / nvdifrec</span>
        <span class="chip">Transforms.json</span>
        <span class="chip">3D Reconstruction</span>
      </div>
    </section>
  </section>
  